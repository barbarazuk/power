{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>VAR</th>\n",
       "      <th>dewpti</th>\n",
       "      <th>hum</th>\n",
       "      <th>pressurei</th>\n",
       "      <th>rain</th>\n",
       "      <th>tempi</th>\n",
       "      <th>thunder</th>\n",
       "      <th>Day</th>\n",
       "      <th>Holiday</th>\n",
       "      <th>PCA_1</th>\n",
       "      <th>low_time</th>\n",
       "      <th>high_time</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>DateIdx</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>2016-05-01 00:00:00</td>\n",
       "      <td>24.25751</td>\n",
       "      <td>62.30</td>\n",
       "      <td>82.000000</td>\n",
       "      <td>29.960000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>67.500000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>-15.419709</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2016-05-01 00:15:00</td>\n",
       "      <td>25.38191</td>\n",
       "      <td>49.85</td>\n",
       "      <td>84.458356</td>\n",
       "      <td>29.832557</td>\n",
       "      <td>0.0</td>\n",
       "      <td>67.257999</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>198.166945</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2016-05-01 00:30:00</td>\n",
       "      <td>25.10542</td>\n",
       "      <td>62.60</td>\n",
       "      <td>88.000000</td>\n",
       "      <td>29.950000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>66.200000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>104.502454</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                          VAR  dewpti        hum  pressurei  rain      tempi  \\\n",
       "DateIdx                                                                        \n",
       "2016-05-01 00:00:00  24.25751   62.30  82.000000  29.960000   0.0  67.500000   \n",
       "2016-05-01 00:15:00  25.38191   49.85  84.458356  29.832557   0.0  67.257999   \n",
       "2016-05-01 00:30:00  25.10542   62.60  88.000000  29.950000   0.0  66.200000   \n",
       "\n",
       "                     thunder  Day  Holiday       PCA_1  low_time  high_time  \n",
       "DateIdx                                                                      \n",
       "2016-05-01 00:00:00      0.0    1        0  -15.419709         0          0  \n",
       "2016-05-01 00:15:00      0.0    1        0  198.166945         0          0  \n",
       "2016-05-01 00:30:00      0.0    1        0  104.502454         0          0  "
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# load the new file\n",
    "import pandas as pd\n",
    "\n",
    "from datetime import date\n",
    "import calendar\n",
    "\n",
    "datasett = pd.read_csv('timeseries3.csv', sep=',', header=0, infer_datetime_format=True, parse_dates=True, index_col=0)\n",
    "from datetime import date\n",
    "datasett['Date'] = datasett['Date'].astype('datetime64[ns]')\n",
    "datasett['month'] = datasett['Date'].apply(lambda x: x.month)\n",
    "\n",
    "datasett['time_of_day'] = datasett['Date'].apply(lambda x: x.time())\n",
    "datasett['hour_of_day'] = datasett['time_of_day'].apply(lambda x: x.hour)\n",
    "datasett = pd.get_dummies(datasett, columns=['hour_of_day'])\n",
    "datasett = datasett.drop(['time_of_day'], axis=1)\n",
    "\n",
    "datasett['low_time'] = datasett['hour_of_day_2'] | datasett['hour_of_day_3'] | datasett['hour_of_day_4'] | datasett['hour_of_day_5']\n",
    "datasett['high_time'] = datasett['hour_of_day_18'] | datasett['hour_of_day_19'] | datasett['hour_of_day_20']\n",
    "\n",
    "datasett = datasett.drop(['month'], axis=1)\n",
    "\n",
    "datasett = datasett.drop(['hour_of_day_0'], axis=1)\n",
    "datasett = datasett.drop(['hour_of_day_1'], axis=1)\n",
    "datasett = datasett.drop(['hour_of_day_2'], axis=1)\n",
    "datasett = datasett.drop(['hour_of_day_3'], axis=1)\n",
    "datasett = datasett.drop(['hour_of_day_4'], axis=1)\n",
    "datasett = datasett.drop(['hour_of_day_5'], axis=1)\n",
    "datasett = datasett.drop(['hour_of_day_6'], axis=1)\n",
    "datasett = datasett.drop(['hour_of_day_7'], axis=1)\n",
    "datasett = datasett.drop(['hour_of_day_8'], axis=1)\n",
    "datasett = datasett.drop(['hour_of_day_9'], axis=1)\n",
    "datasett = datasett.drop(['hour_of_day_10'], axis=1)\n",
    "datasett = datasett.drop(['hour_of_day_11'], axis=1)\n",
    "datasett = datasett.drop(['hour_of_day_12'], axis=1)\n",
    "datasett = datasett.drop(['hour_of_day_13'], axis=1)\n",
    "datasett = datasett.drop(['hour_of_day_14'], axis=1)\n",
    "datasett = datasett.drop(['hour_of_day_15'], axis=1)\n",
    "datasett = datasett.drop(['hour_of_day_16'], axis=1)\n",
    "datasett = datasett.drop(['hour_of_day_17'], axis=1)\n",
    "datasett = datasett.drop(['hour_of_day_18'], axis=1)\n",
    "datasett = datasett.drop(['hour_of_day_19'], axis=1)\n",
    "datasett = datasett.drop(['hour_of_day_20'], axis=1)\n",
    "datasett = datasett.drop(['hour_of_day_21'], axis=1)\n",
    "datasett = datasett.drop(['hour_of_day_22'], axis=1)\n",
    "datasett = datasett.drop(['hour_of_day_23'], axis=1)\n",
    "\n",
    "datasett = datasett.drop(['Date'], axis=1)\n",
    "datasett.head(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "number_of_days = 350\n",
    "epochs_nbr     = 30\n",
    "n_input        = 672\n",
    "starting_point=34272-(number_of_days*96)\n",
    "\n",
    "# normal test\n",
    "i1, i2, i3, i4 = starting_point, 34272, 34272, 34368\n",
    "\n",
    "# try day before the normal test\n",
    "# i1, i2, i3, i4 = starting_point - 96, 34272 - 96, 34272 - 96, 34368 - 96\n",
    "\n",
    "# try 2 days before the normal test\n",
    "# i1, i2, i3, i4 = starting_point - 96*2, 34272 - 96*2, 34272 - 96*2, 34368 - 96*2\n",
    "\n",
    "# try 3 days before the normal test\n",
    "# i1, i2, i3, i4 = starting_point - 96*3, 34272 - 96*3, 34272 - 96*3, 34368 - 96*3\n",
    "\n",
    "\n",
    "# multi headed multi-step cnn for the power usage dataset\n",
    "from math import sqrt\n",
    "from numpy import split\n",
    "from numpy import array\n",
    "from pandas import read_csv\n",
    "from sklearn.metrics import mean_squared_error\n",
    "from matplotlib import pyplot\n",
    "from keras.utils.vis_utils import plot_model\n",
    "from keras.layers import Dense\n",
    "from keras.layers import Flatten\n",
    "from keras.layers.convolutional import Conv1D\n",
    "from keras.layers.convolutional import MaxPooling1D\n",
    "from keras.models import Model\n",
    "from keras.layers import Input\n",
    "from keras.layers.merge import concatenate\n",
    "\n",
    "# split a univariate dataset into train/test sets\n",
    "def split_dataset(data):\n",
    "    # split into standard weeks\n",
    "    train, test = data[i1:i2], data[i3:i4]\n",
    "    # restructure into windows of weekly data\n",
    "    train = array(split(train, len(train)/96))\n",
    "    test = array(split(test, len(test)/96))\n",
    "    return train, test\n",
    "\n",
    "# evaluate one or more weekly forecasts against expected values\n",
    "def evaluate_forecasts(actual, predicted):\n",
    "    scores = list()\n",
    "    # calculate an RMSE score for each day\n",
    "    for i in range(actual.shape[1]): # shape[1] gets the number rows\n",
    "        # calculate mse\n",
    "        mse = mean_squared_error(actual[:, i], predicted[:, i]) # get i'th column, and all rows\n",
    "        # calculate rmse\n",
    "        rmse = sqrt(mse)\n",
    "        # store\n",
    "        scores.append(rmse)\n",
    "    # calculate overall RMSE\n",
    "    s = 0\n",
    "    for row in range(actual.shape[0]):\n",
    "        for col in range(actual.shape[1]):\n",
    "            s += (actual[row, col] - predicted[row, col])**2\n",
    "    score = sqrt(s / (actual.shape[0] * actual.shape[1]))\n",
    "    return score, scores\n",
    "\n",
    "# summarize scores\n",
    "def summarize_scores(name, score, scores):\n",
    "    s_scores = ', '.join(['%.1f' % s for s in scores])\n",
    "    print('%s: [%.3f] %s' % (name, score, s_scores))\n",
    "\n",
    "# convert history into inputs and outputs\n",
    "def to_supervised(train, n_input, n_out=96):\n",
    "    # flatten data\n",
    "    data = train.reshape((train.shape[0]*train.shape[1], train.shape[2]))\n",
    "    X, y = list(), list()\n",
    "    in_start = 0\n",
    "    # step over the entire history one time step at a time\n",
    "    for _ in range(len(data)):\n",
    "        # define the end of the input sequence\n",
    "        in_end = in_start + n_input\n",
    "        out_end = in_end + n_out\n",
    "        # ensure we have enough data for this instance\n",
    "        if out_end <= len(data):\n",
    "            X.append(data[in_start:in_end, :])\n",
    "            y.append(data[in_end:out_end, 0])\n",
    "        # move along one time step\n",
    "        in_start += 1\n",
    "    return array(X), array(y)\n",
    "\n",
    "# train the model\n",
    "def build_model(train, n_input):\n",
    "    # prepare data\n",
    "    train_x, train_y = to_supervised(train, n_input)\n",
    "    # define parameters\n",
    "    verbose, epochs, batch_size = 2, epochs_nbr, 16\n",
    "    n_timesteps, n_features = train_x.shape[1], train_x.shape[2]\n",
    "    n_outputs = train_y.shape[1]\n",
    "    # create a channel for each variable\n",
    "    in_layers, out_layers = list(), list()\n",
    "    for _ in range(n_features):\n",
    "        inputs = Input(shape=(n_timesteps,1))\n",
    "        conv1 = Conv1D(32, 3, activation='relu')(inputs)\n",
    "        conv2 = Conv1D(32, 3, activation='relu')(conv1)\n",
    "        pool1 = MaxPooling1D()(conv2)\n",
    "        flat = Flatten()(pool1)\n",
    "        # store layers\n",
    "        in_layers.append(inputs)\n",
    "        out_layers.append(flat)\n",
    "    # merge heads\n",
    "    merged = concatenate(out_layers)\n",
    "    # interpretation\n",
    "    dense1 = Dense(200, activation='relu')(merged)\n",
    "    dense2 = Dense(100, activation='relu')(dense1)\n",
    "    outputs = Dense(n_outputs)(dense2)\n",
    "    model = Model(inputs=in_layers, outputs=outputs)\n",
    "    # compile model\n",
    "    model.compile(loss='mse', optimizer='adam')\n",
    "    # fit network\n",
    "    input_data = [train_x[:,:,i].reshape((train_x.shape[0],n_timesteps,1)) \n",
    "                  for i in range(n_features)]\n",
    "    model.fit(input_data, train_y, epochs=epochs, \n",
    "              batch_size=batch_size, verbose=verbose)\n",
    "    return model\n",
    "\n",
    "# make a forecast\n",
    "def forecast(model, history, n_input):\n",
    "    # flatten data\n",
    "    data = array(history)\n",
    "    data = data.reshape((data.shape[0]*data.shape[1], data.shape[2]))\n",
    "    # retrieve last observations for input data\n",
    "    input_x = data[-n_input:, :]\n",
    "    # reshape into n input arrays\n",
    "    input_x = [input_x[:,i].reshape((1,input_x.shape[0],1)) for i in range(input_x.shape[1])]\n",
    "    # forecast the next week\n",
    "    yhat = model.predict(input_x, verbose=2)\n",
    "    # we only want the vector forecast\n",
    "    yhat = yhat[0]\n",
    "    return yhat\n",
    "\n",
    "# load the new file\n",
    "dataset = datasett\n",
    "\n",
    "# split into train and test\n",
    "train, test = split_dataset(dataset.values)\n",
    "\n",
    "# evaluate model and get scores\n",
    "\n",
    "#score, scores = evaluate_model(train, test, n_input)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[21.43974494934082,\n",
       " 21.35433006286621,\n",
       " 21.456422805786133,\n",
       " 21.563411712646484,\n",
       " 21.629920959472656,\n",
       " 21.54561424255371,\n",
       " 21.442773818969727,\n",
       " 21.336212158203125,\n",
       " 21.116044998168945,\n",
       " 21.19214630126953,\n",
       " 20.790861129760742,\n",
       " 20.529294967651367,\n",
       " 20.236862182617188,\n",
       " 20.14304542541504,\n",
       " 19.826204299926758,\n",
       " 19.53729820251465,\n",
       " 19.453079223632812,\n",
       " 19.321828842163086,\n",
       " 19.268226623535156,\n",
       " 18.962446212768555,\n",
       " 18.528297424316406,\n",
       " 18.13018798828125,\n",
       " 17.701148986816406,\n",
       " 17.352025985717773,\n",
       " 16.9786434173584,\n",
       " 16.82727813720703,\n",
       " 16.680095672607422,\n",
       " 16.641740798950195,\n",
       " 16.79139518737793,\n",
       " 17.067047119140625,\n",
       " 17.37692642211914,\n",
       " 17.87432861328125,\n",
       " 18.669706344604492,\n",
       " 19.07497787475586,\n",
       " 19.7342472076416,\n",
       " 20.310012817382812,\n",
       " 20.91786003112793,\n",
       " 21.319677352905273,\n",
       " 21.504121780395508,\n",
       " 21.661882400512695,\n",
       " 21.794178009033203,\n",
       " 21.8226261138916,\n",
       " 21.85040283203125,\n",
       " 21.80544090270996,\n",
       " 21.821189880371094,\n",
       " 21.74934959411621,\n",
       " 21.590518951416016,\n",
       " 21.33043670654297,\n",
       " 21.32560157775879,\n",
       " 21.124927520751953,\n",
       " 21.522619247436523,\n",
       " 21.719459533691406,\n",
       " 21.58230972290039,\n",
       " 21.96633529663086,\n",
       " 22.08892822265625,\n",
       " 22.072532653808594,\n",
       " 22.096111297607422,\n",
       " 22.24471664428711,\n",
       " 22.299333572387695,\n",
       " 22.28122901916504,\n",
       " 22.256343841552734,\n",
       " 22.33159828186035,\n",
       " 22.381668090820312,\n",
       " 22.268203735351562,\n",
       " 22.03217315673828,\n",
       " 21.819873809814453,\n",
       " 21.787715911865234,\n",
       " 21.793415069580078,\n",
       " 21.91096305847168,\n",
       " 22.059900283813477,\n",
       " 22.141071319580078,\n",
       " 22.526058197021484,\n",
       " 22.877233505249023,\n",
       " 23.26590347290039,\n",
       " 23.744441986083984,\n",
       " 24.127267837524414,\n",
       " 24.221403121948242,\n",
       " 24.276124954223633,\n",
       " 24.266447067260742,\n",
       " 24.089645385742188,\n",
       " 23.949491500854492,\n",
       " 23.632490158081055,\n",
       " 23.374801635742188,\n",
       " 22.94881820678711,\n",
       " 22.48501968383789,\n",
       " 22.126731872558594,\n",
       " 21.630382537841797,\n",
       " 21.496540069580078,\n",
       " 21.215967178344727,\n",
       " 21.09596061706543,\n",
       " 21.001567840576172,\n",
       " 21.058277130126953,\n",
       " 20.917951583862305,\n",
       " 21.105382919311523,\n",
       " 21.19220733642578,\n",
       " 21.195693969726562]"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "yhat_sequence.tolist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[21.170400619506836,\n",
       " 21.084739685058594,\n",
       " 21.126239776611328,\n",
       " 21.20359230041504,\n",
       " 21.238359451293945,\n",
       " 21.065258026123047,\n",
       " 20.837303161621094,\n",
       " 20.62456703186035,\n",
       " 20.322912216186523,\n",
       " 20.350330352783203,\n",
       " 19.89147186279297,\n",
       " 19.54164695739746,\n",
       " 19.202707290649414,\n",
       " 18.952856063842773,\n",
       " 18.528785705566406,\n",
       " 18.183460235595703,\n",
       " 18.09791374206543,\n",
       " 18.074634552001953,\n",
       " 18.206335067749023,\n",
       " 18.156829833984375,\n",
       " 18.143293380737305,\n",
       " 18.28551483154297,\n",
       " 18.419567108154297,\n",
       " 18.796079635620117,\n",
       " 19.1159610748291,\n",
       " 19.699132919311523,\n",
       " 20.177223205566406,\n",
       " 20.697202682495117,\n",
       " 21.237133026123047,\n",
       " 21.759349822998047,\n",
       " 22.04967498779297,\n",
       " 22.337528228759766,\n",
       " 22.81922721862793,\n",
       " 22.694957733154297,\n",
       " 22.71135711669922,\n",
       " 22.60078239440918,\n",
       " 22.488000869750977,\n",
       " 22.22136688232422,\n",
       " 21.754140853881836,\n",
       " 21.440248489379883,\n",
       " 21.17209243774414,\n",
       " 20.956661224365234,\n",
       " 20.933069229125977,\n",
       " 20.97305679321289,\n",
       " 21.167640686035156,\n",
       " 21.348358154296875,\n",
       " 21.533899307250977,\n",
       " 21.59904670715332,\n",
       " 21.96353530883789,\n",
       " 22.110904693603516,\n",
       " 22.74660873413086,\n",
       " 23.20798110961914,\n",
       " 23.318843841552734,\n",
       " 23.84427833557129,\n",
       " 24.03309440612793,\n",
       " 24.017963409423828,\n",
       " 24.01007080078125,\n",
       " 24.086883544921875,\n",
       " 24.063770294189453,\n",
       " 24.053152084350586,\n",
       " 24.134721755981445,\n",
       " 24.289073944091797,\n",
       " 24.501708984375,\n",
       " 24.631351470947266,\n",
       " 24.68308448791504,\n",
       " 24.76799774169922,\n",
       " 25.08171272277832,\n",
       " 25.440780639648438,\n",
       " 25.79033088684082,\n",
       " 26.139833450317383,\n",
       " 26.354951858520508,\n",
       " 26.80517578125,\n",
       " 27.13446617126465,\n",
       " 27.473020553588867,\n",
       " 27.846097946166992,\n",
       " 28.12593650817871,\n",
       " 28.1324520111084,\n",
       " 28.03257942199707,\n",
       " 27.88172721862793,\n",
       " 27.66530418395996,\n",
       " 27.414709091186523,\n",
       " 26.946733474731445,\n",
       " 26.6245174407959,\n",
       " 26.1241455078125,\n",
       " 25.57924461364746,\n",
       " 25.11724281311035,\n",
       " 24.479896545410156,\n",
       " 24.264116287231445,\n",
       " 23.880084991455078,\n",
       " 23.634510040283203,\n",
       " 23.363800048828125,\n",
       " 23.303239822387695,\n",
       " 23.053211212158203,\n",
       " 23.235092163085938,\n",
       " 23.346500396728516,\n",
       " 23.313249588012695]"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "next_week = forecast(model, history, n_input)\n",
    "next_week.tolist()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Double check the length of the training set before and after appending the test set."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "252"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "history = [x for x in train]\n",
    "predictions = list()\n",
    "len(history)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "253"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "for i in range(len(test)):\n",
    "    # predict the week\n",
    "    yhat_sequence = forecast(model, history, n_input)\n",
    "    # store the predictions\n",
    "    predictions.append(yhat_sequence)\n",
    "    # get real observation and add to history for predicting the next week\n",
    "    history.append(test[i, :])\n",
    "len(history)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "TensorFlow-GPU",
   "language": "python",
   "name": "tf-gpu"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
